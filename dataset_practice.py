# -*- coding: utf-8 -*-
"""dataset_practice.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WWpgnRcNj7Nog5I-Z4Zus7udCgexC_ZL

# **Загрузка датасета**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import drive 
drive.mount('/content/gdrive')

data = pd.read_csv('gdrive/My Drive/Colab Notebooks/master.csv')
data.head()

"""# **Изучение датасета**"""

# вывод размерности
data.shape

# вывод столбцов
data.columns

# переименование столбцов для удобства
data.columns = ['country', 'year', 'gender', 'age_group', 'suicide_count', 'population', 'suicide_rate', 'country-year', 'HDI for year',
                'gdp_for_year', 'gdp_per_capita', 'generation']
data.columns

# вывод информации о датасете
data.info()

"""# **Исключение пустых значений**"""

data.isnull().any()

# исключение столбца "индекса человеческого развития", 
# так как треть данных для него отсутствует
data=data.drop(['HDI for year'],axis=1)
# исключение столбца с названием страны и годом, 
# так как эти данные дублируют данные в соответствующих столбцах
data = data.drop(['country-year'],axis=1)

# проверка на остаточные строки с пустыми значениями

data = data.dropna()

data.head()

"""# **Визуализация данных**"""

# вывод графиков каждого из факторов, представленных в цифрах
data.hist(bins = 50,figsize = (15,11))

# вывод графика населения для каждой страны в 1985 году

min_year=min(data.year)
max_year=max(data.year)

data_country=data[(data['year']==min_year)]
country_1985_population=[]

country_1985=data[(data['year']==min_year)].country.unique()

for country in country_1985:
    country_1985_population.append(sum(data_country[(data_country['country']==country)].population)) 

plt.figure(figsize=(10,10))
sns.barplot(y=country_1985,x=country_1985_population)
plt.xlabel('Population Count')
plt.ylabel('Countries')
plt.title('1985 Year Sum Population for Suicide Rate')
plt.show()

# вывод графика по гендерам и возрастным группам

data.age_group.value_counts()

plt.figure(figsize=(10,5))
sns.countplot(data.gender,hue=data.age_group)
plt.title('Gender & Age')
plt.show()

# вывод сравнительного графика стран по количеству суицидов

suicides_count=[]
for country in data.country.unique():
    suicides_count.append(sum(data[data['country']==country].suicide_count))  

suicides_count=pd.DataFrame(suicides_count,columns=['suicide_count'])
country=pd.DataFrame(data.country.unique(),columns=['country'])
data_suicide_countr=pd.concat([suicides_count,country],axis=1)

data_suicide_countr=data_suicide_countr.sort_values(by='suicide_count',ascending=False)

sns.barplot(y=data_suicide_countr.country[:15],x=data_suicide_countr.suicide_count[:15])
plt.show()

# вывод соотношения гендеров среди данных за каждое поколение
plt.figure(figsize=(10,5))
sns.countplot(data.generation,hue=data.gender)
plt.title('Generation hue Gender Counter')
plt.show()

plt.figure(figsize=(10,5))
sns.set_color_codes("muted")
sns.barplot(x="year", y="suicide_count", data=data,
            label="Year Suicides", color="b")
plt.xticks(rotation=90)
plt.show()

# вывод соотношения количества людей по поколениям
data['generation'].value_counts().plot.pie(explode=[0.1,0.1,0.1,0.1,0.1,0.1],
                                           autopct='%1.1f%%',shadow=True, figsize=(18,8)).set_title('Generations Count')

# вывод соотношения ВВП страны к количеству суицидов
fig=sns.jointplot(y='gdp_per_capita',x='suicide_count',height=7, kind='hex',data=data[data['country']=='Russian Federation'], color="k")

plt.show()

# вывод соотношения количества суицидов к количеству суицидов на 100 тыс населения
sns.jointplot("suicide_rate", "suicide_count", data=data[data['country']=='Russian Federation'], kind="kde",space=0,color='g')
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# вывод соотношения количества суицидов к ВВП в зависимости от года

import matplotlib.pyplot as plt
# %matplotlib inline
sns.FacetGrid(data,hue='year',size=5).map(plt.scatter,'gdp_per_capita','suicide_rate').add_legend()
plt.show()

# вывод гендерного соотношения количества суицидов

sns.lineplot(x="suicide_count", y="suicide_rate",
             hue="gender",data=data.sort_values(by='suicide_rate',ascending=False))
plt.show()

"""# **Подготовка данных**"""

# построение матрицы корреляции

plt.figure(figsize=(7,5))
sns.heatmap(data.corr(), annot=True, cmap='Oranges')
plt.show()

# вывод зависимости количества суицидов от года

data[['year','suicide_rate']].groupby(['year']).sum().plot()

# вывод основных характеристик для каждого из факторов

data.describe()

# исключение выбросов

data=data.sort_values(by=["suicide_rate"])
q1=data["suicide_rate"].quantile(0.25)
q3=data["suicide_rate"].quantile(0.75)
iqr=q3-q1
lwo=q1-1.5*iqr
upo=q3+1.5*iqr
data=data[(data.suicide_rate<upo)&(data.suicide_rate>lwo)]
data=data.sort_index().reset_index(drop=True)
data.shape

# создание копии датасета

stat_data = data.copy()
stat_data

# конвертирование данных в числовые значения, создание фиктивных переменных

from sklearn.preprocessing import LabelEncoder
import pickle
file = open('label.pkl', 'wb')
categorical = ['country','year','age_group', 'gender', 'generation']
dict= {}

for column in categorical:
    le = LabelEncoder()
    le.fit(stat_data[column])
    # dump information to that file
    dict[column] = le
    stat_data[column] = le.transform(stat_data[column])
pickle.dump(dict, file)
file.close()

file = open('label.pkl', "rb")
label = pickle.load(file)
label

# проверка типа данных

stat_data.dtypes

# исправление типа данных на float

stat_data['gdp_for_year'] = stat_data['gdp_for_year'].str.replace(',','').astype(float)

# масштабирование данных

numerical = ['suicide_count', 'population', 'gdp_for_year','gdp_per_capita']

from sklearn.preprocessing import RobustScaler

rc = RobustScaler()
stat_data[numerical] = rc.fit_transform(stat_data[numerical])

import pickle
pickle.dump(rc, open('robust.pkl', "wb"))

y = stat_data['suicide_rate']
X = stat_data.drop('suicide_rate',axis=1)
# X.shape, y.shape

stat_data

# разделение датасета на датасеты для обучения и теста в отношении 80-20

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)
X_train.shape, X_test.shape

"""# **Прогнозирование с помощью многослойного персептрона**"""

from sklearn.neural_network import MLPRegressor
mlp = MLPRegressor(hidden_layer_sizes=([100,100]))
mlp.fit(X_train, y_train)

y_test_mlp = mlp.predict(X_test)
y_train_mlp = mlp.predict(X_train)

# оценка модели

from sklearn.metrics import mean_squared_error

acc_train_mlp = mlp.score(X_train, y_train)
acc_test_mlp = mlp.score(X_test, y_test)

# вычисление среднеквадратичной ошибки
rmse_train_mlp = np.sqrt(mean_squared_error(y_train, y_train_mlp))
rmse_test_mlp = np.sqrt(mean_squared_error(y_test, y_test_mlp))

print("Точность данных для обучения: {:.3f}".format(acc_train_mlp))
print("Точность данных для тестирования: {:.3f}".format(acc_test_mlp))
print('\nСреднеквадратичное отклонение тренировочного набора данных: ', rmse_train_mlp)
print('Среднеквадратичное отклонение тестового набора данных: ', rmse_test_mlp)

plt.scatter(y_train,y_train_mlp)
plt.xlabel("Actual Value")
plt.ylabel("Predicted Value")
plt.title("Actual vs Predicted Training Set")